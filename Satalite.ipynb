{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Satalite.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOZo2yC93W6/mqncwTI5Byh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajayaram92/Satalite-Prediction/blob/main/Satalite.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idLsHn_hWULo"
      },
      "source": [
        "\r\n",
        "import requests\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "from scipy import stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-3D1Z0PWg3I"
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/ajayaram92/Satalite-Prediction/main/Database.csv\"\r\n",
        "df = pd.read_csv(url)\r\n",
        "df = df.drop([\"objID\"], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBnZ1agcXs6P",
        "outputId": "0090da70-8d0d-4076-d085-5686e2794444"
      },
      "source": [
        "def cleaning(df, column):\r\n",
        "  column_names = df.columns\r\n",
        "   \r\n",
        "  new_columns= (list(column_names[0:15])) \r\n",
        "  new_columns.append(column)\r\n",
        "  #new_columns.append(str(column + \" Category\"))\r\n",
        "  new_pd = df[new_columns].dropna().reset_index()\r\n",
        "  new_pd = new_pd.drop([\"index\"], axis = 1)\r\n",
        "  return((new_pd))\r\n",
        "\r\n",
        "data = cleaning(df, \"pH\")\r\n",
        "print(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Longitude   Latitude      B1   B10  ...      B8     B8A     B9    pH\n",
            "0     77.812500  18.751111  1482.0  21.0  ...  1464.5  1705.5  393.5  7.25\n",
            "1     77.433900  18.351600  1409.5  15.5  ...  1338.5  1495.0  352.0  7.18\n",
            "2     77.433900  18.350800  1415.0  16.0  ...  1334.5  1579.5  365.0  7.63\n",
            "3     77.558857  18.314899  1377.0  25.5  ...  1090.0  1247.0  323.5  7.48\n",
            "4     78.018333  19.870278  1424.0  11.0  ...  2106.0  2388.5  542.5  8.41\n",
            "...         ...        ...     ...   ...  ...     ...     ...    ...   ...\n",
            "9801  77.451160  19.241660  1408.0  11.5  ...  1747.5  2035.0  440.5  8.72\n",
            "9802  77.422618  18.327200  1378.5  16.0  ...  1372.0  1554.0  358.0  7.52\n",
            "9803  77.823333  18.843889  1449.5  21.0  ...  1458.0  1667.5  375.5  7.00\n",
            "9804  77.517882  18.467689  1442.5  14.5  ...  1731.0  2014.0  445.0  7.43\n",
            "9805  77.524953  18.538106  1425.5  17.5  ...  1436.0  1692.0  354.0  7.42\n",
            "\n",
            "[9806 rows x 16 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOUs-vrBAAs-"
      },
      "source": [
        "def normalize(x, mean, std):\r\n",
        "  return ((x-mean)/std)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8Cb7NJju6Or"
      },
      "source": [
        "def splitting(data,training_split=0.8):\r\n",
        "  data = data.drop([\"Longitude\", \"Latitude\"], axis=1)\r\n",
        "  data = data.to_numpy()\r\n",
        "  np.random.shuffle(data)\r\n",
        "  train_set= data[0:int(len(data)*training_split)]\r\n",
        "  test_set = data[int(len(data)*training_split):]\r\n",
        "  mean = train_set.mean(axis = 0)\r\n",
        "  std = train_set.std(axis = 0)\r\n",
        "  \r\n",
        "  train_set = normalize(train_set, mean, std)\r\n",
        "  test_set = normalize(test_set, mean, std)\r\n",
        "  \r\n",
        "  def output(array):\r\n",
        "    output_array = array[:,-1]\r\n",
        "    array = np.delete(array, -1, axis=1)\r\n",
        "    return(array, output_array)\r\n",
        "\r\n",
        "  train_set, train_output = output(train_set)\r\n",
        "  test_set, test_output = output(test_set)\r\n",
        "\r\n",
        "  return(train_set, train_output, test_set, test_output, mean, std)\r\n",
        "  \r\n",
        "\r\n",
        "train_set, train_output, test_set, test_output, mean, std = splitting(data)\r\n",
        "  \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMLTlePeCrlU",
        "outputId": "632640a3-f392-4125-91e6-b33d6c6bb3be"
      },
      "source": [
        "\r\n",
        "#print(train_set)\r\n",
        "print(train_output.shape)\r\n",
        "print(train_set.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7844,)\n",
            "(7844, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJXEZG8PCUt9"
      },
      "source": [
        "\r\n",
        "Layer = tf.keras.layers\r\n",
        "model = tf.keras.models.Sequential([Layer.Dense(13, input_shape=(13,)),\r\n",
        "                                    Layer.Dense(1)])\r\n",
        "optimizer = tf.keras.optimizers.SGD(lr=1e-7, momentum=0.9)\r\n",
        "loss = tf.keras.losses.MeanSquaredError()\r\n",
        "model.compile(optimizer=optimizer, loss=loss, )\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "td5FqMnwJNyL",
        "outputId": "36e8bbc1-4874-43aa-80fb-7ce0380f1886"
      },
      "source": [
        "tf.keras.backend.clear_session()\r\n",
        "history = model.fit(train_set, train_output, epochs=500, validation_data=(test_set, test_output))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "246/246 [==============================] - 1s 2ms/step - loss: 1.4356 - val_loss: 6.1412\n",
            "Epoch 2/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.0167 - val_loss: 6.1374\n",
            "Epoch 3/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 3.0436 - val_loss: 6.1336\n",
            "Epoch 4/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.5617 - val_loss: 6.1300\n",
            "Epoch 5/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8822 - val_loss: 6.1265\n",
            "Epoch 6/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.9024 - val_loss: 6.1230\n",
            "Epoch 7/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.3224 - val_loss: 6.1197\n",
            "Epoch 8/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.7307 - val_loss: 6.1163\n",
            "Epoch 9/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.7513 - val_loss: 6.1131\n",
            "Epoch 10/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.2646 - val_loss: 6.1099\n",
            "Epoch 11/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.0290 - val_loss: 6.1068\n",
            "Epoch 12/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.7061 - val_loss: 6.1038\n",
            "Epoch 13/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9057 - val_loss: 6.1009\n",
            "Epoch 14/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.0001 - val_loss: 6.0980\n",
            "Epoch 15/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8035 - val_loss: 6.0951\n",
            "Epoch 16/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8106 - val_loss: 6.0923\n",
            "Epoch 17/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8289 - val_loss: 6.0896\n",
            "Epoch 18/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.4261 - val_loss: 6.0870\n",
            "Epoch 19/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.0207 - val_loss: 6.0844\n",
            "Epoch 20/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9504 - val_loss: 6.0818\n",
            "Epoch 21/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.2774 - val_loss: 6.0793\n",
            "Epoch 22/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8304 - val_loss: 6.0768\n",
            "Epoch 23/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8720 - val_loss: 6.0744\n",
            "Epoch 24/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.0404 - val_loss: 6.0720\n",
            "Epoch 25/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.8389 - val_loss: 6.0696\n",
            "Epoch 26/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9323 - val_loss: 6.0673\n",
            "Epoch 27/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8655 - val_loss: 6.0651\n",
            "Epoch 28/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.0215 - val_loss: 6.0628\n",
            "Epoch 29/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.0852 - val_loss: 6.0607\n",
            "Epoch 30/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.1212 - val_loss: 6.0586\n",
            "Epoch 31/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7800 - val_loss: 6.0565\n",
            "Epoch 32/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.3907 - val_loss: 6.0545\n",
            "Epoch 33/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.5405 - val_loss: 6.0525\n",
            "Epoch 34/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.9605 - val_loss: 6.0505\n",
            "Epoch 35/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.5085 - val_loss: 6.0486\n",
            "Epoch 36/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 3.0085 - val_loss: 6.0466\n",
            "Epoch 37/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.1633 - val_loss: 6.0448\n",
            "Epoch 38/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.1594 - val_loss: 6.0429\n",
            "Epoch 39/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.1359 - val_loss: 6.0411\n",
            "Epoch 40/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.2176 - val_loss: 6.0393\n",
            "Epoch 41/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.2839 - val_loss: 6.0376\n",
            "Epoch 42/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9580 - val_loss: 6.0358\n",
            "Epoch 43/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.8478 - val_loss: 6.0341\n",
            "Epoch 44/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.0120 - val_loss: 6.0325\n",
            "Epoch 45/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9231 - val_loss: 6.0308\n",
            "Epoch 46/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8578 - val_loss: 6.0292\n",
            "Epoch 47/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.7468 - val_loss: 6.0276\n",
            "Epoch 48/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.4040 - val_loss: 6.0260\n",
            "Epoch 49/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.6119 - val_loss: 6.0245\n",
            "Epoch 50/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9051 - val_loss: 6.0229\n",
            "Epoch 51/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.3602 - val_loss: 6.0214\n",
            "Epoch 52/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.0712 - val_loss: 6.0199\n",
            "Epoch 53/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.1587 - val_loss: 6.0184\n",
            "Epoch 54/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.3259 - val_loss: 6.0170\n",
            "Epoch 55/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.8234 - val_loss: 6.0155\n",
            "Epoch 56/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.0863 - val_loss: 6.0141\n",
            "Epoch 57/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8229 - val_loss: 6.0127\n",
            "Epoch 58/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.7328 - val_loss: 6.0114\n",
            "Epoch 59/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8449 - val_loss: 6.0100\n",
            "Epoch 60/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7960 - val_loss: 6.0086\n",
            "Epoch 61/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7939 - val_loss: 6.0073\n",
            "Epoch 62/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.0113 - val_loss: 6.0060\n",
            "Epoch 63/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8503 - val_loss: 6.0047\n",
            "Epoch 64/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.2883 - val_loss: 6.0034\n",
            "Epoch 65/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8259 - val_loss: 6.0021\n",
            "Epoch 66/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7483 - val_loss: 6.0009\n",
            "Epoch 67/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8488 - val_loss: 5.9996\n",
            "Epoch 68/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.4950 - val_loss: 5.9984\n",
            "Epoch 69/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.1484 - val_loss: 5.9972\n",
            "Epoch 70/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.6230 - val_loss: 5.9960\n",
            "Epoch 71/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.0003 - val_loss: 5.9948\n",
            "Epoch 72/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.0646 - val_loss: 5.9936\n",
            "Epoch 73/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7893 - val_loss: 5.9924\n",
            "Epoch 74/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.7574 - val_loss: 5.9913\n",
            "Epoch 75/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.1380 - val_loss: 5.9902\n",
            "Epoch 76/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.2360 - val_loss: 5.9890\n",
            "Epoch 77/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.3889 - val_loss: 5.9879\n",
            "Epoch 78/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.2593 - val_loss: 5.9868\n",
            "Epoch 79/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.4158 - val_loss: 5.9857\n",
            "Epoch 80/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 3.4186 - val_loss: 5.9846\n",
            "Epoch 81/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.2002 - val_loss: 5.9835\n",
            "Epoch 82/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7798 - val_loss: 5.9824\n",
            "Epoch 83/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7420 - val_loss: 5.9814\n",
            "Epoch 84/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.2631 - val_loss: 5.9803\n",
            "Epoch 85/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.4822 - val_loss: 5.9793\n",
            "Epoch 86/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8062 - val_loss: 5.9782\n",
            "Epoch 87/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.6223 - val_loss: 5.9772\n",
            "Epoch 88/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.0917 - val_loss: 5.9762\n",
            "Epoch 89/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.0801 - val_loss: 5.9752\n",
            "Epoch 90/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.1041 - val_loss: 5.9741\n",
            "Epoch 91/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9210 - val_loss: 5.9732\n",
            "Epoch 92/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7764 - val_loss: 5.9722\n",
            "Epoch 93/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.3355 - val_loss: 5.9712\n",
            "Epoch 94/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.6978 - val_loss: 5.9702\n",
            "Epoch 95/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7811 - val_loss: 5.9692\n",
            "Epoch 96/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8151 - val_loss: 5.9683\n",
            "Epoch 97/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.2342 - val_loss: 5.9673\n",
            "Epoch 98/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.1216 - val_loss: 5.9663\n",
            "Epoch 99/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7197 - val_loss: 5.9654\n",
            "Epoch 100/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8183 - val_loss: 5.9645\n",
            "Epoch 101/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.5427 - val_loss: 5.9635\n",
            "Epoch 102/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.0203 - val_loss: 5.9626\n",
            "Epoch 103/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.6694 - val_loss: 5.9617\n",
            "Epoch 104/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.1297 - val_loss: 5.9608\n",
            "Epoch 105/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.4240 - val_loss: 5.9598\n",
            "Epoch 106/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.6998 - val_loss: 5.9589\n",
            "Epoch 107/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.6676 - val_loss: 5.9580\n",
            "Epoch 108/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.1084 - val_loss: 5.9571\n",
            "Epoch 109/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9664 - val_loss: 5.9562\n",
            "Epoch 110/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 3.4010 - val_loss: 5.9554\n",
            "Epoch 111/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.3858 - val_loss: 5.9545\n",
            "Epoch 112/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.7053 - val_loss: 5.9536\n",
            "Epoch 113/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.7177 - val_loss: 5.9527\n",
            "Epoch 114/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.5872 - val_loss: 5.9519\n",
            "Epoch 115/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.0021 - val_loss: 5.9510\n",
            "Epoch 116/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7931 - val_loss: 5.9501\n",
            "Epoch 117/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.3378 - val_loss: 5.9493\n",
            "Epoch 118/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.4115 - val_loss: 5.9484\n",
            "Epoch 119/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.9778 - val_loss: 5.9476\n",
            "Epoch 120/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9890 - val_loss: 5.9467\n",
            "Epoch 121/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7356 - val_loss: 5.9459\n",
            "Epoch 122/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7103 - val_loss: 5.9450\n",
            "Epoch 123/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8775 - val_loss: 5.9442\n",
            "Epoch 124/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.6859 - val_loss: 5.9434\n",
            "Epoch 125/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.6939 - val_loss: 5.9425\n",
            "Epoch 126/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7982 - val_loss: 5.9417\n",
            "Epoch 127/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.3894 - val_loss: 5.9409\n",
            "Epoch 128/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.3832 - val_loss: 5.9401\n",
            "Epoch 129/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.0755 - val_loss: 5.9393\n",
            "Epoch 130/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.8429 - val_loss: 5.9385\n",
            "Epoch 131/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.3839 - val_loss: 5.9377\n",
            "Epoch 132/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.2625 - val_loss: 5.9368\n",
            "Epoch 133/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.0387 - val_loss: 5.9360\n",
            "Epoch 134/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.6259 - val_loss: 5.9352\n",
            "Epoch 135/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.1000 - val_loss: 5.9345\n",
            "Epoch 136/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7901 - val_loss: 5.9337\n",
            "Epoch 137/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.3307 - val_loss: 5.9329\n",
            "Epoch 138/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.6925 - val_loss: 5.9321\n",
            "Epoch 139/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.2318 - val_loss: 5.9313\n",
            "Epoch 140/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 4.2889 - val_loss: 5.9305\n",
            "Epoch 141/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.3793 - val_loss: 5.9298\n",
            "Epoch 142/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.1365 - val_loss: 5.9290\n",
            "Epoch 143/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7344 - val_loss: 5.9282\n",
            "Epoch 144/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9056 - val_loss: 5.9274\n",
            "Epoch 145/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.0545 - val_loss: 5.9267\n",
            "Epoch 146/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.6831 - val_loss: 5.9259\n",
            "Epoch 147/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8006 - val_loss: 5.9252\n",
            "Epoch 148/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7919 - val_loss: 5.9244\n",
            "Epoch 149/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.3370 - val_loss: 5.9236\n",
            "Epoch 150/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.6603 - val_loss: 5.9229\n",
            "Epoch 151/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9838 - val_loss: 5.9221\n",
            "Epoch 152/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.3024 - val_loss: 5.9214\n",
            "Epoch 153/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.8619 - val_loss: 5.9206\n",
            "Epoch 154/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.4452 - val_loss: 5.9199\n",
            "Epoch 155/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8477 - val_loss: 5.9191\n",
            "Epoch 156/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.0468 - val_loss: 5.9184\n",
            "Epoch 157/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.0247 - val_loss: 5.9177\n",
            "Epoch 158/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.6947 - val_loss: 5.9169\n",
            "Epoch 159/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9150 - val_loss: 5.9162\n",
            "Epoch 160/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.8922 - val_loss: 5.9154\n",
            "Epoch 161/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8507 - val_loss: 5.9147\n",
            "Epoch 162/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8524 - val_loss: 5.9140\n",
            "Epoch 163/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.8119 - val_loss: 5.9132\n",
            "Epoch 164/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.3198 - val_loss: 5.9125\n",
            "Epoch 165/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7246 - val_loss: 5.9118\n",
            "Epoch 166/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7950 - val_loss: 5.9111\n",
            "Epoch 167/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8394 - val_loss: 5.9103\n",
            "Epoch 168/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.5077 - val_loss: 5.9096\n",
            "Epoch 169/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.1007 - val_loss: 5.9089\n",
            "Epoch 170/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8921 - val_loss: 5.9082\n",
            "Epoch 171/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.0713 - val_loss: 5.9075\n",
            "Epoch 172/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 5.0048 - val_loss: 5.9068\n",
            "Epoch 173/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8173 - val_loss: 5.9061\n",
            "Epoch 174/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 3.4575 - val_loss: 5.9054\n",
            "Epoch 175/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.6814 - val_loss: 5.9047\n",
            "Epoch 176/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7932 - val_loss: 5.9039\n",
            "Epoch 177/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 3.5034 - val_loss: 5.9032\n",
            "Epoch 178/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7457 - val_loss: 5.9025\n",
            "Epoch 179/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.4306 - val_loss: 5.9018\n",
            "Epoch 180/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.8739 - val_loss: 5.9011\n",
            "Epoch 181/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.7766 - val_loss: 5.9004\n",
            "Epoch 182/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 3.1249 - val_loss: 5.8998\n",
            "Epoch 183/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.3429 - val_loss: 5.8991\n",
            "Epoch 184/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9294 - val_loss: 5.8984\n",
            "Epoch 185/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.3837 - val_loss: 5.8977\n",
            "Epoch 186/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.6905 - val_loss: 5.8970\n",
            "Epoch 187/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8146 - val_loss: 5.8963\n",
            "Epoch 188/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8922 - val_loss: 5.8956\n",
            "Epoch 189/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.4620 - val_loss: 5.8950\n",
            "Epoch 190/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8136 - val_loss: 5.8943\n",
            "Epoch 191/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7479 - val_loss: 5.8936\n",
            "Epoch 192/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8177 - val_loss: 5.8929\n",
            "Epoch 193/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7278 - val_loss: 5.8922\n",
            "Epoch 194/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.6532 - val_loss: 5.8915\n",
            "Epoch 195/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.6988 - val_loss: 5.8908\n",
            "Epoch 196/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.4350 - val_loss: 5.8902\n",
            "Epoch 197/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.4068 - val_loss: 5.8895\n",
            "Epoch 198/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9066 - val_loss: 5.8888\n",
            "Epoch 199/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.5293 - val_loss: 5.8882\n",
            "Epoch 200/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9675 - val_loss: 5.8875\n",
            "Epoch 201/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7895 - val_loss: 5.8868\n",
            "Epoch 202/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.8570 - val_loss: 5.8862\n",
            "Epoch 203/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.7850 - val_loss: 5.8855\n",
            "Epoch 204/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7066 - val_loss: 5.8848\n",
            "Epoch 205/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9923 - val_loss: 5.8842\n",
            "Epoch 206/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 3.5365 - val_loss: 5.8835\n",
            "Epoch 207/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.9939 - val_loss: 5.8829\n",
            "Epoch 208/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.4498 - val_loss: 5.8822\n",
            "Epoch 209/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.6472 - val_loss: 5.8816\n",
            "Epoch 210/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7389 - val_loss: 5.8809\n",
            "Epoch 211/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.3101 - val_loss: 5.8802\n",
            "Epoch 212/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 1.3402 - val_loss: 5.8796\n",
            "Epoch 213/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.2608 - val_loss: 5.8789\n",
            "Epoch 214/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.6799 - val_loss: 5.8783\n",
            "Epoch 215/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.4516 - val_loss: 5.8776\n",
            "Epoch 216/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.7340 - val_loss: 5.8770\n",
            "Epoch 217/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 1.4735 - val_loss: 5.8764\n",
            "Epoch 218/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.3164 - val_loss: 5.8757\n",
            "Epoch 219/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 1.1375 - val_loss: 5.8751\n",
            "Epoch 220/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 2.6284 - val_loss: 5.8744\n",
            "Epoch 221/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.8098 - val_loss: 5.8738\n",
            "Epoch 222/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.0780 - val_loss: 5.8732\n",
            "Epoch 223/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 1.1955 - val_loss: 5.8725\n",
            "Epoch 224/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.7346 - val_loss: 5.8719\n",
            "Epoch 225/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8066 - val_loss: 5.8712\n",
            "Epoch 226/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8222 - val_loss: 5.8706\n",
            "Epoch 227/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7244 - val_loss: 5.8700\n",
            "Epoch 228/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.3576 - val_loss: 5.8693\n",
            "Epoch 229/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.2043 - val_loss: 5.8687\n",
            "Epoch 230/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.3733 - val_loss: 5.8681\n",
            "Epoch 231/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 1.2861 - val_loss: 5.8674\n",
            "Epoch 232/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 1.3058 - val_loss: 5.8668\n",
            "Epoch 233/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.2003 - val_loss: 5.8662\n",
            "Epoch 234/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8393 - val_loss: 5.8656\n",
            "Epoch 235/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.5471 - val_loss: 5.8649\n",
            "Epoch 236/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 1.2188 - val_loss: 5.8643\n",
            "Epoch 237/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.6537 - val_loss: 5.8637\n",
            "Epoch 238/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8754 - val_loss: 5.8631\n",
            "Epoch 239/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.3699 - val_loss: 5.8625\n",
            "Epoch 240/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.0060 - val_loss: 5.8618\n",
            "Epoch 241/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.6364 - val_loss: 5.8612\n",
            "Epoch 242/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 1.0926 - val_loss: 5.8606\n",
            "Epoch 243/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9791 - val_loss: 5.8600\n",
            "Epoch 244/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.4827 - val_loss: 5.8594\n",
            "Epoch 245/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.9138 - val_loss: 5.8588\n",
            "Epoch 246/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.0289 - val_loss: 5.8582\n",
            "Epoch 247/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.1817 - val_loss: 5.8575\n",
            "Epoch 248/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.6690 - val_loss: 5.8569\n",
            "Epoch 249/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9956 - val_loss: 5.8563\n",
            "Epoch 250/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.6673 - val_loss: 5.8557\n",
            "Epoch 251/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.1843 - val_loss: 5.8551\n",
            "Epoch 252/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.0122 - val_loss: 5.8545\n",
            "Epoch 253/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 1.5264 - val_loss: 5.8539\n",
            "Epoch 254/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.6984 - val_loss: 5.8533\n",
            "Epoch 255/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.5020 - val_loss: 5.8527\n",
            "Epoch 256/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.6667 - val_loss: 5.8521\n",
            "Epoch 257/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.3208 - val_loss: 5.8515\n",
            "Epoch 258/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8983 - val_loss: 5.8509\n",
            "Epoch 259/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.0259 - val_loss: 5.8503\n",
            "Epoch 260/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9434 - val_loss: 5.8497\n",
            "Epoch 261/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 3.0760 - val_loss: 5.8491\n",
            "Epoch 262/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.1696 - val_loss: 5.8485\n",
            "Epoch 263/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.3553 - val_loss: 5.8479\n",
            "Epoch 264/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.7858 - val_loss: 5.8473\n",
            "Epoch 265/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.2286 - val_loss: 5.8467\n",
            "Epoch 266/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.2800 - val_loss: 5.8461\n",
            "Epoch 267/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.6177 - val_loss: 5.8455\n",
            "Epoch 268/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 1.5055 - val_loss: 5.8449\n",
            "Epoch 269/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.0508 - val_loss: 5.8443\n",
            "Epoch 270/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 1.7570 - val_loss: 5.8437\n",
            "Epoch 271/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.6458 - val_loss: 5.8432\n",
            "Epoch 272/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7598 - val_loss: 5.8426\n",
            "Epoch 273/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.4123 - val_loss: 5.8420\n",
            "Epoch 274/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8946 - val_loss: 5.8414\n",
            "Epoch 275/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.2927 - val_loss: 5.8408\n",
            "Epoch 276/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 2.4579 - val_loss: 5.8402\n",
            "Epoch 277/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.0019 - val_loss: 5.8397\n",
            "Epoch 278/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.4779 - val_loss: 5.8391\n",
            "Epoch 279/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9134 - val_loss: 5.8385\n",
            "Epoch 280/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7756 - val_loss: 5.8379\n",
            "Epoch 281/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 3.1674 - val_loss: 5.8374\n",
            "Epoch 282/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.4455 - val_loss: 5.8368\n",
            "Epoch 283/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.5770 - val_loss: 5.8362\n",
            "Epoch 284/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 2.3690 - val_loss: 5.8356\n",
            "Epoch 285/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.3183 - val_loss: 5.8350\n",
            "Epoch 286/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 3.1602 - val_loss: 5.8345\n",
            "Epoch 287/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8175 - val_loss: 5.8339\n",
            "Epoch 288/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 4.1984 - val_loss: 5.8333\n",
            "Epoch 289/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.2336 - val_loss: 5.8328\n",
            "Epoch 290/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8131 - val_loss: 5.8322\n",
            "Epoch 291/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.3109 - val_loss: 5.8316\n",
            "Epoch 292/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.5610 - val_loss: 5.8311\n",
            "Epoch 293/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.6819 - val_loss: 5.8305\n",
            "Epoch 294/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.6464 - val_loss: 5.8299\n",
            "Epoch 295/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.8457 - val_loss: 5.8294\n",
            "Epoch 296/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 4.9235 - val_loss: 5.8288\n",
            "Epoch 297/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.6285 - val_loss: 5.8283\n",
            "Epoch 298/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.6406 - val_loss: 5.8277\n",
            "Epoch 299/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.4757 - val_loss: 5.8271\n",
            "Epoch 300/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7395 - val_loss: 5.8266\n",
            "Epoch 301/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7389 - val_loss: 5.8260\n",
            "Epoch 302/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.9691 - val_loss: 5.8255\n",
            "Epoch 303/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.6716 - val_loss: 5.8249\n",
            "Epoch 304/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8044 - val_loss: 5.8244\n",
            "Epoch 305/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 3.4438 - val_loss: 5.8238\n",
            "Epoch 306/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.5028 - val_loss: 5.8233\n",
            "Epoch 307/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.3551 - val_loss: 5.8227\n",
            "Epoch 308/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.8894 - val_loss: 5.8222\n",
            "Epoch 309/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 1.7016 - val_loss: 5.8216\n",
            "Epoch 310/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.1749 - val_loss: 5.8211\n",
            "Epoch 311/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9171 - val_loss: 5.8205\n",
            "Epoch 312/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 3.3030 - val_loss: 5.8200\n",
            "Epoch 313/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.5361 - val_loss: 5.8194\n",
            "Epoch 314/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.2963 - val_loss: 5.8189\n",
            "Epoch 315/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.4497 - val_loss: 5.8184\n",
            "Epoch 316/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9811 - val_loss: 5.8178\n",
            "Epoch 317/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8657 - val_loss: 5.8173\n",
            "Epoch 318/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.6827 - val_loss: 5.8167\n",
            "Epoch 319/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.6498 - val_loss: 5.8162\n",
            "Epoch 320/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.6652 - val_loss: 5.8157\n",
            "Epoch 321/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 1.5555 - val_loss: 5.8151\n",
            "Epoch 322/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.8271 - val_loss: 5.8146\n",
            "Epoch 323/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 1.5292 - val_loss: 5.8141\n",
            "Epoch 324/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7760 - val_loss: 5.8135\n",
            "Epoch 325/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.8039 - val_loss: 5.8130\n",
            "Epoch 326/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.6230 - val_loss: 5.8125\n",
            "Epoch 327/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9610 - val_loss: 5.8119\n",
            "Epoch 328/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.6839 - val_loss: 5.8114\n",
            "Epoch 329/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9655 - val_loss: 5.8109\n",
            "Epoch 330/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7107 - val_loss: 5.8103\n",
            "Epoch 331/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.8874 - val_loss: 5.8098\n",
            "Epoch 332/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.2163 - val_loss: 5.8093\n",
            "Epoch 333/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.8272 - val_loss: 5.8087\n",
            "Epoch 334/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 1.7970 - val_loss: 5.8082\n",
            "Epoch 335/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8140 - val_loss: 5.8077\n",
            "Epoch 336/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.2026 - val_loss: 5.8072\n",
            "Epoch 337/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.5663 - val_loss: 5.8066\n",
            "Epoch 338/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 1.2157 - val_loss: 5.8061\n",
            "Epoch 339/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.6913 - val_loss: 5.8056\n",
            "Epoch 340/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.7721 - val_loss: 5.8051\n",
            "Epoch 341/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.5587 - val_loss: 5.8046\n",
            "Epoch 342/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.8647 - val_loss: 5.8040\n",
            "Epoch 343/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.3024 - val_loss: 5.8035\n",
            "Epoch 344/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7100 - val_loss: 5.8030\n",
            "Epoch 345/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.9322 - val_loss: 5.8025\n",
            "Epoch 346/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.9039 - val_loss: 5.8020\n",
            "Epoch 347/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9656 - val_loss: 5.8015\n",
            "Epoch 348/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.7757 - val_loss: 5.8010\n",
            "Epoch 349/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9013 - val_loss: 5.8004\n",
            "Epoch 350/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.7635 - val_loss: 5.7999\n",
            "Epoch 351/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.5327 - val_loss: 5.7994\n",
            "Epoch 352/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 1.0487 - val_loss: 5.7989\n",
            "Epoch 353/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.8718 - val_loss: 5.7984\n",
            "Epoch 354/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 1.4837 - val_loss: 5.7979\n",
            "Epoch 355/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.7695 - val_loss: 5.7974\n",
            "Epoch 356/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.5973 - val_loss: 5.7969\n",
            "Epoch 357/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.9688 - val_loss: 5.7964\n",
            "Epoch 358/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.7812 - val_loss: 5.7959\n",
            "Epoch 359/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.0278 - val_loss: 5.7954\n",
            "Epoch 360/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9668 - val_loss: 5.7949\n",
            "Epoch 361/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 1.7002 - val_loss: 5.7944\n",
            "Epoch 362/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.1231 - val_loss: 5.7938\n",
            "Epoch 363/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.4379 - val_loss: 5.7933\n",
            "Epoch 364/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.7021 - val_loss: 5.7928\n",
            "Epoch 365/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.5779 - val_loss: 5.7924\n",
            "Epoch 366/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.0776 - val_loss: 5.7918\n",
            "Epoch 367/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 1.7382 - val_loss: 5.7913\n",
            "Epoch 368/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 1.2552 - val_loss: 5.7908\n",
            "Epoch 369/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.7829 - val_loss: 5.7903\n",
            "Epoch 370/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7702 - val_loss: 5.7898\n",
            "Epoch 371/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.6701 - val_loss: 5.7894\n",
            "Epoch 372/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.5527 - val_loss: 5.7889\n",
            "Epoch 373/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.1604 - val_loss: 5.7884\n",
            "Epoch 374/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9967 - val_loss: 5.7879\n",
            "Epoch 375/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.1723 - val_loss: 5.7874\n",
            "Epoch 376/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 1.2836 - val_loss: 5.7869\n",
            "Epoch 377/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9251 - val_loss: 5.7864\n",
            "Epoch 378/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.6462 - val_loss: 5.7859\n",
            "Epoch 379/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8027 - val_loss: 5.7854\n",
            "Epoch 380/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.0761 - val_loss: 5.7849\n",
            "Epoch 381/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.4674 - val_loss: 5.7844\n",
            "Epoch 382/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9455 - val_loss: 5.7839\n",
            "Epoch 383/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7536 - val_loss: 5.7835\n",
            "Epoch 384/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 1.3851 - val_loss: 5.7830\n",
            "Epoch 385/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.8111 - val_loss: 5.7825\n",
            "Epoch 386/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 1.0621 - val_loss: 5.7820\n",
            "Epoch 387/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.1227 - val_loss: 5.7815\n",
            "Epoch 388/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7085 - val_loss: 5.7810\n",
            "Epoch 389/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.6969 - val_loss: 5.7806\n",
            "Epoch 390/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 3.5753 - val_loss: 5.7801\n",
            "Epoch 391/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 3.0246 - val_loss: 5.7796\n",
            "Epoch 392/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.9412 - val_loss: 5.7791\n",
            "Epoch 393/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.6120 - val_loss: 5.7786\n",
            "Epoch 394/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.6976 - val_loss: 5.7782\n",
            "Epoch 395/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 2.5160 - val_loss: 5.7777\n",
            "Epoch 396/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.0430 - val_loss: 5.7772\n",
            "Epoch 397/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.5904 - val_loss: 5.7767\n",
            "Epoch 398/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.6287 - val_loss: 5.7763\n",
            "Epoch 399/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 1.5489 - val_loss: 5.7758\n",
            "Epoch 400/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.4667 - val_loss: 5.7753\n",
            "Epoch 401/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7396 - val_loss: 5.7748\n",
            "Epoch 402/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.0414 - val_loss: 5.7744\n",
            "Epoch 403/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 1.3866 - val_loss: 5.7739\n",
            "Epoch 404/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8965 - val_loss: 5.7734\n",
            "Epoch 405/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.0504 - val_loss: 5.7730\n",
            "Epoch 406/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.6461 - val_loss: 5.7725\n",
            "Epoch 407/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7448 - val_loss: 5.7720\n",
            "Epoch 408/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.6848 - val_loss: 5.7715\n",
            "Epoch 409/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.8151 - val_loss: 5.7711\n",
            "Epoch 410/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.9770 - val_loss: 5.7706\n",
            "Epoch 411/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 2.9520 - val_loss: 5.7701\n",
            "Epoch 412/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.2474 - val_loss: 5.7697\n",
            "Epoch 413/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9353 - val_loss: 5.7692\n",
            "Epoch 414/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.9129 - val_loss: 5.7688\n",
            "Epoch 415/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7865 - val_loss: 5.7683\n",
            "Epoch 416/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8657 - val_loss: 5.7678\n",
            "Epoch 417/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.7206 - val_loss: 5.7674\n",
            "Epoch 418/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 1.1225 - val_loss: 5.7669\n",
            "Epoch 419/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8133 - val_loss: 5.7664\n",
            "Epoch 420/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.6856 - val_loss: 5.7660\n",
            "Epoch 421/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.9427 - val_loss: 5.7655\n",
            "Epoch 422/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.7413 - val_loss: 5.7651\n",
            "Epoch 423/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 1.7325 - val_loss: 5.7646\n",
            "Epoch 424/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 1.3589 - val_loss: 5.7642\n",
            "Epoch 425/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8103 - val_loss: 5.7637\n",
            "Epoch 426/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8606 - val_loss: 5.7632\n",
            "Epoch 427/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8773 - val_loss: 5.7628\n",
            "Epoch 428/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.6888 - val_loss: 5.7623\n",
            "Epoch 429/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8426 - val_loss: 5.7619\n",
            "Epoch 430/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.3729 - val_loss: 5.7614\n",
            "Epoch 431/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.2087 - val_loss: 5.7610\n",
            "Epoch 432/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.6026 - val_loss: 5.7605\n",
            "Epoch 433/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.7242 - val_loss: 5.7601\n",
            "Epoch 434/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.6398 - val_loss: 5.7596\n",
            "Epoch 435/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.5765 - val_loss: 5.7592\n",
            "Epoch 436/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7974 - val_loss: 5.7587\n",
            "Epoch 437/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.6434 - val_loss: 5.7583\n",
            "Epoch 438/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.6904 - val_loss: 5.7578\n",
            "Epoch 439/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.1627 - val_loss: 5.7574\n",
            "Epoch 440/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.0640 - val_loss: 5.7569\n",
            "Epoch 441/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.9353 - val_loss: 5.7565\n",
            "Epoch 442/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8826 - val_loss: 5.7561\n",
            "Epoch 443/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.9228 - val_loss: 5.7556\n",
            "Epoch 444/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7930 - val_loss: 5.7552\n",
            "Epoch 445/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.6382 - val_loss: 5.7547\n",
            "Epoch 446/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9153 - val_loss: 5.7543\n",
            "Epoch 447/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.2476 - val_loss: 5.7538\n",
            "Epoch 448/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7089 - val_loss: 5.7534\n",
            "Epoch 449/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.5535 - val_loss: 5.7530\n",
            "Epoch 450/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7173 - val_loss: 5.7525\n",
            "Epoch 451/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.8517 - val_loss: 5.7521\n",
            "Epoch 452/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9656 - val_loss: 5.7516\n",
            "Epoch 453/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.5931 - val_loss: 5.7512\n",
            "Epoch 454/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.6430 - val_loss: 5.7508\n",
            "Epoch 455/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.1993 - val_loss: 5.7503\n",
            "Epoch 456/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.9737 - val_loss: 5.7499\n",
            "Epoch 457/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.5440 - val_loss: 5.7495\n",
            "Epoch 458/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 2.2243 - val_loss: 5.7490\n",
            "Epoch 459/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.3722 - val_loss: 5.7486\n",
            "Epoch 460/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 2.2845 - val_loss: 5.7482\n",
            "Epoch 461/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.9492 - val_loss: 5.7477\n",
            "Epoch 462/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.6485 - val_loss: 5.7473\n",
            "Epoch 463/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.6598 - val_loss: 5.7469\n",
            "Epoch 464/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7909 - val_loss: 5.7465\n",
            "Epoch 465/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 1.6240 - val_loss: 5.7460\n",
            "Epoch 466/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.1464 - val_loss: 5.7456\n",
            "Epoch 467/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.7131 - val_loss: 5.7452\n",
            "Epoch 468/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.1978 - val_loss: 5.7447\n",
            "Epoch 469/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.8777 - val_loss: 5.7443\n",
            "Epoch 470/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9398 - val_loss: 5.7439\n",
            "Epoch 471/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.8874 - val_loss: 5.7435\n",
            "Epoch 472/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9043 - val_loss: 5.7430\n",
            "Epoch 473/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 1.9961 - val_loss: 5.7426\n",
            "Epoch 474/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9017 - val_loss: 5.7422\n",
            "Epoch 475/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.9709 - val_loss: 5.7418\n",
            "Epoch 476/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.6168 - val_loss: 5.7413\n",
            "Epoch 477/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.5116 - val_loss: 5.7409\n",
            "Epoch 478/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 1.2211 - val_loss: 5.7405\n",
            "Epoch 479/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.8070 - val_loss: 5.7401\n",
            "Epoch 480/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.8625 - val_loss: 5.7396\n",
            "Epoch 481/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.2319 - val_loss: 5.7392\n",
            "Epoch 482/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9412 - val_loss: 5.7388\n",
            "Epoch 483/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.9811 - val_loss: 5.7384\n",
            "Epoch 484/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 1.0022 - val_loss: 5.7380\n",
            "Epoch 485/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.8020 - val_loss: 5.7375\n",
            "Epoch 486/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 2.6417 - val_loss: 5.7371\n",
            "Epoch 487/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 2.2847 - val_loss: 5.7367\n",
            "Epoch 488/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.7380 - val_loss: 5.7363\n",
            "Epoch 489/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.6413 - val_loss: 5.7359\n",
            "Epoch 490/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.3683 - val_loss: 5.7355\n",
            "Epoch 491/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9976 - val_loss: 5.7351\n",
            "Epoch 492/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.9485 - val_loss: 5.7346\n",
            "Epoch 493/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.7933 - val_loss: 5.7342\n",
            "Epoch 494/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 0.8830 - val_loss: 5.7338\n",
            "Epoch 495/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.9566 - val_loss: 5.7334\n",
            "Epoch 496/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 0.6518 - val_loss: 5.7330\n",
            "Epoch 497/500\n",
            "246/246 [==============================] - 0s 2ms/step - loss: 1.5270 - val_loss: 5.7326\n",
            "Epoch 498/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 2.0448 - val_loss: 5.7322\n",
            "Epoch 499/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.1148 - val_loss: 5.7318\n",
            "Epoch 500/500\n",
            "246/246 [==============================] - 0s 1ms/step - loss: 1.6072 - val_loss: 5.7314\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "41M_LhMOL8AI",
        "outputId": "0355ffb8-768d-4f62-9d0e-f9293009acbd"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "loss = history.history['loss']\r\n",
        "val_loss = history.history['val_loss']\r\n",
        "\r\n",
        "epochs = range(len(loss))\r\n",
        "\r\n",
        "\r\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\r\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\r\n",
        "plt.title('Training and validation loss')\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}